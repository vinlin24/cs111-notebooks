<!-- COM SCI 111: Operating System Principles -->


# Lecture 01 - 01/10/2023


## What is an Operating System?


### What is an OS?


* A system software intended to provide support for higher level applications, primarily user processes.
* "Its purpose is to *help* you run *other* software."
* A software that sits between the hardware and everything else, hiding the nasty details.
* Allows easy, safe, fair use and sharing of resources.
* Practically every computing device has an operating system, even things like smart fridges. Anything with a CPU inside likely has an operating system.


### How do you work with an OS?


* You configure them for a particular purpose you have.
* You use their features when you write *programs*, from things as simple as "printing" to the console, dealing with file I/O, etc.
* You rely on *services* they offer including:
  * Memory management
  * Persistent storage
  * Scheduling and synchronization
  * Interprocess communications (IPC)
  * Security


### What Does an OS Do?


* Manages hardware for programs (allocation, sharing, execution, handling problems, etc.).
  * For example, dividing by zero safely *crashes your program* instead of bringing down your whole computer thanks to the OS.
* Abstracts hardware to make it easier for use and portability. It also optimizes performance.
  * For example, saving bytes in a buffer instead of writing it directly to disk to minimize performance overhead.
* Provides new abstractions for applications, making it easier for developers to write software programs intended to run atop the OS.


### What Does an OS Look Like?


Abstraction:

* CPU: bytes, shorts, pointers, adding, subtracting, etc.
* OS: files, processes, threads, devices, ports, etc.
* Applications: such objects and their services

The OS effectively *extends* a computer, creating a much richer virtual computing platform and more powerful operations.


## Why Learn Operating Systems?


Many hard problems have been tackled in the context of operating systems:
* How to coordinate separate computatinons
* How to manage shared resources
* How to virtualize hardware and software
* How to organize communications
* How to protect your computing resources

Notice that this list is very general. The operating system solutions are often applicable to programs and systems you write, so understanding them is useful to have in your toolbelt.


## General OS Wisdom


Stuff we can learn from what has been applied to developing operating systems.


### Interface vs. Implementation


An important concept is to separate the **interface** (what the user interacts with, "porcelain") and the **implementation** (how it is constructed under the hood, "plumbing").

**Interfaces** are formal definitions for how software/hardware components work.

**Implementations** are the code that achieves the expected effects defined by the interfaces.

* An implementation is *not* a specification.
* Many compliant implementations are possible for a certain interface.
* Therefore, do *not* depend on the implementation, as it may change.
* In contrast, an interface specification is a *contract* with the users.
* This is the basis for product/release **interoperability**.

> Occasionally companies like Microsoft change the interface for some important software. These changes are often *controversial*, but they can get away with it because they're a tech giant. If just anyone attempts to break this contract, their software is most likely going to become very unpopular

> People have software that works a particular way. Nobody wants to change because it's expensive, and everything already works. A good example of this is how most of the world still uses IPv4 instead of upgrading to IPv6. This exemplifies how hard it is to *change* an interface, *particularly* a network interface.
>
> Network protocols are very, *very* interface-dependent because both sides of a communication line have to agree on exactly how to encode and transmit some sequence of bits.


### Modularity and Functional Encapsulation


Hide complexity with an appropriate level of abstraction. This allows you to encapsulate certain aspects of the implementation and only have to worry about interacting with *that* module's **interface** instead of worrying about its internals. This takes a massive **cognitive load** off the developer and in turn makes code more maintainable and expandable.

**Spaghetti code** is when code becomes very messy due to poor complexity management. Features depend excessively on each other, so changes in one area of code could cause a cascade of unexpected changes, making the code very hard to maintain.

**Object-oriented programming (OOP)** is an example of modular programming. It's a convenient, easy-to-learn paradigm we often take for granted in the modern age with languages like Python, Java, C++, etc. The speed of processors these days are so fast that the overhead (extra instructions and redundancies introduced by abstraction) make negligible difference.

Operating systems don't use OOP however, and this is just because performance is of the utmost importance, so they need to use languages that give them a finer level of control (vs. abstraction), usually C.


### Separate Policy from Mechanism


* **Policy** determines what can/should be done. Example: scheduling.
* **Mechanism** implements basic operations to do it. Example: (how to implement scheduling). <!-- lol thanks -->
* Mechanisms shouldn't dictate or limit policies.
* Policies must be *changeable* without changing mechanisms.
* You define a policy and then implement some mechanisms for that policy.

This is kind of analogous to interface ("policy") vs. implementation ("mechanism"), I think?

"An interface is a specification description of your software and policies are like settings."

> Policy and mechanism example: absence or presence of **user interactivity** in a weather simulation vs. presentation slides. For the former, you don't have to worry about listening for events like mouse clicks, so you don't need to run any instructions related to it, allowing the simulation to take advantage of the full computing power. For the latter, displaying slides is interactive - the presenter may click the screen/move their laser pointer at unpredictable intervals. The OS would observe that scenario through its interface and *change its policy* to make sure such events are handled. I think? Kind of didn't listen too hard.


### Parallelism


**Parallelism** and **asynchronicity** are powerful and vital, but dangerous when used carelessly. This is often the source of **nondeterministic** errors.

This is often associated with multi-core processing, but it has been important since the topic of scheduling.

Parallelism is needed to implement the semblance of multiple things happening at the same time, like rendering a video game with shadows, character movement, etc.


### Some Other Points


View services as objects and operations, and behind every object is a **data structure**.

Performance and correctness are often at odds. One often needs to be sacrificed in favor of the other.

> There was a Linux kernel bug a while ago: "Dirty CoW" (copy-on-write). It was there because an existing implementation in the OS was wrong, but the chances of it malfunctioning was very small, so developers didn't fix it because it may have had a performance implication. People then figured out how to *exploit* this vulnerability.


# Lecture 01 (Continued) - 01/12/2023


```
                    Application software

          ----- Application Binary Interface -----

                  System Services/Libraries

bleh

Privileged instruction set    Standard instruction set

                        Hardware
```

At the library level, libc converts source code level system calls into binary system calls that can use the OS' API.

The operating system is the only layer in the abstractions that is allowed to use the **privileged instruction set** (in addition to the **standard instruction set**).

The OS is automatically loaded when the machine boots and should *always* be present while the computer is running, ready to run when it's needed. *The OS should NEVER crash because it if does, it takes everything with it.*

The OS isn't actually running *all the time*; it wold be a waste of computing power. It just needs to be *ready* to run, and it passively runs every so often for housekeeping tasks in addition to managing a computer's startup.


## Instruction Set Architectures (ISAs)


These describe the set of instructions supported by a computer, namely which bit patterns (opcodes) correspond to what operations.

They usually come in families. A program written for an ISA will run on any compliant CPU.


### Privileged vs. General Instructions


*Any* code running on the machine can execute **general instructions** *directly* (without requesting from the OS).

A processor must be put into a *special mode* to execute **privileged instructions.** These are instructions that do things that are "dangerous." A certain bit in a register must be set for the processor to execute such instructions, and if it's not, attempting to run them amounts to an error.


## Platforms


The complete set of hardware in the box, of which the OS is one part, and the OS runs atop this platform. The platform includes peripherals like network cards, speakers, etc. Functionality beyond user mode instructions.

A successful OS will run on many ISAs, meaning some customers cannot choose their ISA. This implies that the OS will *abstract* the ISA. This abstraction should make *minimal assumptions* about specific hardware. The OS shouldn't require you to have a specific screen size, specific mouse, etc.


## Binary Distribution Model


OSes are written in source but are typically **distributed** in binary, ready to runs. There are one or more binary distributions per ISA.

**Device drivers** can then be added **after-market**. These can be written and distributed by 3rd parties. Any one driver can work with many versions of the OS.

The first time the OS starts up, it gives you an opportunity to **configure** it.


### Binary Configuration Model


The idea is to eliminate manual/static configuration to enable on distribution to serve all users.

Automatic hardware discovery and resource allocation.

> **Busses** are pieces of hardware that transfer data from one place to another.


## What Functionality Is In the OS?


OS code is very expensive to develop and maintain.

The less code you write in the OS, the less bugs you add to the OS. Remember that the OS must never crash. You should have **as much as necessary, as little as possible** in the OS code.

> An operating system **kernel** is called a "kernel" because it should be small! This is not so true anymore these days, though.

There's a performance cost with moving between user code and operating system. If there is code that needs to make lots of OS requests, that functionality probably has good reason to be built straight into the OS instead.


## Conclusion

* Understanding operating systems is critical to understanding how computers work
* Operating systems interact directly with the hardware
* Operating systems rely on stable interfaces


# Lecture 02 - 01/12/2022


## The OS and Abstractions


One major function of an OS is to offer **abstract** versions of **physical** resources.

* Processes (abstraction) ~ use of CPU/RAM (physical)
* Files (abstraction) ~ flash drives (physical)

These abstractions are more *useful* for application programmers to work with.

* Easier to use than the original resources
* Compartmentalize/encapsulate complexity
* Eliminate behavior that is irrelevant to the user
* Create more convenient behavior

We can *generalize* abstractions to make many different types of hardware and software *appear* the same. This way, many applications can deal with a single common class. This usually involves a common unifying model.

The popular **portable document format (PDF)** is an example that unifies document formatting for printers. Also, printer drivers make different printers look the same.


## Types of OS Resources


### Serially Reusable Resources


Used by multiple clients, but only one at a time (**time multiplexing**). The client currently using it has **exclusive use**. This requires **access control** and **graceful transitions** from one user to the next.


Examples:

* Printers
* Speakers
* Bathrooms!

**What is a graceful transition?**

* No incomplete operations that finish *after* a transition. The first user has to be completely done before moving on the second.
* Every subsequent user should find a resource in a "like new" condition, with no traces of data or state left over from the first user.

Information about a process that is stopped but needs to start back up again is stored in memory somewhere. This is necessary because sometimes a process is stopped to make room for another process on the same core. The former process should be reinitialized with its stack pointer, etc. when it's started up again on that core or even another core.


### Partitionable Resources


Divided into disjoint pieces for multiple clients (**spatial multiplexing**). This also needs **access control** to ensure:

* **Containment**: you cannot access resources *outside* of your **partition.**
* **Privacy**: nobody else can access resources in *your* partition.

Examples:

* RAM
* Hard disk drive
* Hotel rooms!

Still needs graceful transitions because most partitionable resources aren't permanently allocates. As long as a resource is not "yours", sooner or later it's likely to become someone else's, so a transition is required.


### Shareable Resources


Usable by multiple concurrent clients. Clients don't "wait" for acess to a resource, nor do they "own"  a particular subset of the resource. The clients use the resources *at the same time.*

These *appear* as (effectively) limitless resources.

Examples:

* Copy of the OS, shared by all processes
* Air in a room, shared by occupants!

These typically do not need graceful transitions because:

* Shareable resources usually do not *change state* or it isn't "reused". It's **read-only**.
* We never have to clean up what doesn't get dirty, like an execute-only copy of the OS

> **TIP**: Design your system to *maximize* shareable resources.


## Trends in Operating Systems


Their role has fundamentally changed, ultimately because it's to keep up with what users want. Applications have become more complex with more complex internal behavior, interfaces, and interaction with other software.


* **BEFORE**: shepherding the use of hardware.
* **AFTER**: shielding the applications from hardware (abstractions), providing powerful application computing platform, becoming a sophisticated "traffic cop".

Something that hasn't changed is that they still sit between applications and hardware. We still understand them through services that they provide, including:

* Capabilities you add
* Applications they enable
* Problems they eliminate

> Remember the fundamental purpose of the OS is to *help* with complexity.


### Convergence of OSes


OSes are expensive to build and maintain, so the business has a high price of entry. It must also support all the apps the users want for them to choose the OS over other options.

This had led to a convergence of OSes. There are only a handful of widely used OSes, namely (the big three lol):

* Windows (1985)
* MacOS (which is itself a Unix-like system) (1984)
* Linux (which itself descends from Unix as well) (1991)

Among a few special purpose ones like real time and embedded system OSes, like FreeBSD, QNX, and TinyOS.

The big 3 all descend from the same old models developed about 30 years prior.


## OS Services


> All about abstractions!

Basic categories of abstractions:

* CPU/memory abstractions
* Persistent storage abstractions
* Other I/O abstractions

Services: higher level abstractions:

* Cooperating parallel processes
* Security
* User interface

Services: under the covers:

* Enclosure management (monitoring the physical appliances, like managing the computer's fans!)
* Software updates and configuration registry
* Dynamic resource allocation and scheduling
* Networks, protocols, and domain services


